
# DPLNet (Efficient Multimodal Semantic Segmentation via Dual-Prompt Learning)


Welcome to the official code repository for [**Efficient Multimodal Semantic Segmentation via Dual-Prompt Learning**]. We're excited to share our work with you, please bear with us as we prepare the code and demo. Stay tuned for the reveal!


## Motivation
Previous multimodal methods often needs to fully fine-tune the entire network, which is training-costly due to massive parameter updates in the feature extraction and fusion, and thus increases the deployment burden of multimodal semantic segmentation. In this paper, we propose a novel and simple yet effective dual-prompt
learning paradigm, dubbed DPLNet, for training-efficient multimodal semantic segmentation.

<img src="https://github.com/ShaohuaDong2021/DPLNet/blob/main/figs/fig1.png" alt="Editor" width="550" height="350">

## Framework
![Framework](https://github.com/ShaohuaDong2021/DPLNet/blob/main/figs/framework.png)

## Results
### NYU-V2
![Results](https://github.com/ShaohuaDong2021/DPLNet/blob/main/figs/nyuv2.png)

### SUN-RGBD
![Results](https://github.com/ShaohuaDong2021/DPLNet/blob/main/figs/sunrgbd.png)

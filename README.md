
# DPLNet (Efficient Multimodal Semantic Segmentation via Dual-Prompt Learning)


Welcome to the official code repository for [**Efficient Multimodal Semantic Segmentation via Dual-Prompt Learning**]. We're excited to share our work with you, please bear with us as we prepare the code and demo. Stay tuned for the reveal!


## Motivation
Previous multimodal methods often need to fully fine-tune the entire network, which are training-costly due to massive parameter updates in the feature extraction and fusion, and thus increases the deployment burden of multimodal semantic segmentation. In this paper, we propose a novel and simple yet effective dual-prompt
learning paradigm, dubbed DPLNet, for training-efficient multimodal semantic segmentation.

<img src="https://github.com/ShaohuaDong2021/DPLNet/blob/main/figs/fig1.png" alt="Editor" width="500">

## Framework
![Framework](https://github.com/ShaohuaDong2021/DPLNet/blob/main/figs/framework.png)

## RGBD Semantic Segmentation Results
### NYU-V2
![Results](https://github.com/ShaohuaDong2021/DPLNet/blob/main/figs/nyuv2.png)

### SUN-RGBD
![Results](https://github.com/ShaohuaDong2021/DPLNet/blob/main/figs/sunrgbd.png)

## RGBT Semantic Segmentation Results
### MFNet
![Results](https://github.com/ShaohuaDong2021/DPLNet/blob/main/figs/mfnet.png)

### PST900
![Results](https://github.com/ShaohuaDong2021/DPLNet/blob/main/figs/PST900.png)

## RGB-D SOD Results
![Results](https://github.com/ShaohuaDong2021/DPLNet/blob/main/figs/RGBDSOD.png)

## RGB-T SOD Results
![Results](https://github.com/ShaohuaDong2021/DPLNet/blob/main/figs/RGBTSOD.png)

## RGB-T Video Semantic Segmentation Results
![Results](https://github.com/ShaohuaDong2021/DPLNet/blob/main/figs/MVSeg.png)
